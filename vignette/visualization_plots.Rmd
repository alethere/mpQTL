---
title: "Visualization functions"
author: "Alejandro Thérèse Navarro"
output: 
  html_document:
    theme: lumen
    toc: true
    toc_float:
      collapsed: false
    toc_depth: 3
---

In this document we will discuss visualization functions included in `mpQTL` as well as their interpretations. Different types of output will help us understand the data that we work with and their characteristics. The visualizations provided include:

1. Principal Coordinate Analysis (PCoA) plots 
2. Quantile-quantile plots (QQ-plots)
3. Manhattan plots (labelled as skyline plots)
4. Phenotype boxplots based on SNP or haplotype dosage

We can distinguish betwen those visualizations useful **before** the QTL analysis (1), those useful to **understand** the QTL analysis (2 and 3), and finally those that help us **dissect** the results of the QTL (4).

Before, however, let us discuss the data structures required in mpQTL.

```{r data_load,echo=F}
source("../R/viz_fun.R")
source("../R/mapQTL_fun.R")
data <- readRDS("workshop_data.RDS")
map <- data$map
phe <- data$pheno
dos <- as.matrix(data$dosage)
hap <- as.matrix(data$founder)
pv <- data$result[[1]]$pval
wald <- data$result[[1]]$wald
```


# Data

The visualization functions are based on different data structures that are also used in the rest of the mpQTL package. In order to introduce these data structures, we will use a sample dataset from a simulated tetraploid population.

*Dosage scores* are represented using a matrix of $markers \times individuals$ so that there are $m$ rows, equal to the number of markers and $n$ columns, equal to the number of individuals. *Haplotype data* is expressed in a similar fashion, with the difference that each each individual is represented by $p$ number of columns, where $p$ is the ploidy. That is, for a tetraploid, each individual has four consecutive columns containing the haplotype type. Haplotypes can be expressed using numeric or character values (e.g. 120, 140, 128...;A, B, C...; hap1, hap2, hap3...). All functions have been tested and developed so that missing values in any of the two matrices can be handled without problems.
```{r gen_tables,echo=F}
rownames(dos) <- map$marker
tab <- knitr::kable(dos[1:10,1:8],format = "html",caption = "Dosages of 8 individuals")
kableExtra::kable_styling(tab,bootstrap_options = c("stripped","hover","condensed"))

tab <- knitr::kable(hap[1:10,1:8],format = "html",caption = "Haplotypes of 2 individuals")
kableExtra::kable_styling(tab,bootstrap_options = c("stripped","hover","condensed"))
```

With any genotypic data (dosages or haplotypes), an adequate genetic map must be provided. Such map is expressed using a simple `data.frame` that must contain at least three columns, "marker" with a marker name; "chromosome" with the chromosome name or number; and "position", with the genetic position of each marker, preferably in cM (although any unit will work). Most functions will assume that the genetic map and the genotypic data are in the same order, that is, that the marker of the first row of the map is the marker of the first row if the genotypic data. 

Unmapped markers can also be included in this map by indicating that they belong to *chromosome 0*. Importantly, they should be given a position as well, the simplest option is to give the first unmapped marker position 1, the second position 2, and so on. 

```{r map_table,echo=F}
tab <- knitr::kable(map[1:10,],format = "html",caption = "Genetic map of the first ten markers")
kableExtra::kable_styling(tab,bootstrap_options = c("stripped","hover","condensed"))
```

*Phenotypes* can be expressed either as a numeric vector or a numeric matrix, where each column is a different phenotype. With both formats the phenotypes can be passed to `map.QTL()` to generate the QTL mapping results. There are many outputs in such results, but for the purpose of this tutorial we will focus only on the *p-value vector*, which contains a p-value score for each marker, again in the same order as the rows of dosage and haplotype matrix and the genetic map.

Lastly, a visualization function has been included for *distance matrices* (such as the K matrix, that we will introduce later). These are based on the genotypic data and can be generated through a multitude of methods (euclidean distance, Nei's...). These square matrices assign a numeric value to the "genetic distance" between two individuals for each pair of individuals in the population, and thus are usually symmetric. Within `mpQTL` a single measure has been included, but any type of distance matrix can be used in the visualization function we will explain below.

# Principal Coordinate Analysis 

## Introduction to PCoA

How does one plot multidimensional data in a 2D space? The answer is simple: multidimensional scaling (MDS)! The definition of MDS, however, is not so simple, so let us not focus on the maths behind it but on their interpretation. MDS methods are a family of scaling procedures that allow to reorganize the variance of a matrix. The most widely known of these methods is Principal Coordinate Analysis (PCoA), of which Principal Component Analysis (PCA) is a special case. We will focus on PCoA for our purposes.

PCoA can intuitively be understood. Each vector in a matrix provides an amount of information that relates to the variance of that vector. However, if two vectors are correlated, they are providing the same information twice, thus, they are not adding more variance to the data matrix. However, there are mathematical procedures (*matrix decomposition*) that allow us to obtain uncorrelated vectors (named **principal components, PC**) from a matrix of correlated vectors, thus, where each vector provides unique information. Furthermore, we can obtain the amount of original information that each vector represents (**percentage of explained variance**). This measure is then used to order the PCs, so that the first component, PC1, explains most of the variance, followed by the second, etc. 

So, from a complex matrix where each vector has some degree of correlation with the other vectors, we can obtain a PC matrix where each vector is uncorrelated and contains as much of the original information as is possible. Thus, if the first 2 components contain, together, 60% of the total variance, we can visualize most of the information in the original matrix in a 2D space!

#### PCoA for genetic data

The genetic similarity between individuals can be expressed with a $n \times n$ distance matrix, where each the amount of differences between individual $i$ and $j$ are quantified with a value at the $d_{ij}$ cell of the matrix (and also at $d_{ji}$). A distance is larger the more different two individuals are, but for the purpose of PCoA one can also use a similarity matrix, where the values are larger the more similar two individuals are. 

There exist multiple methods for calculating genetic distances/similarities, but in the `mpQTL` package we have included a function named `calc.K()` which produces a similarity matrix of individuals. Other distance measures are implemented in R through the function `dist()`, which includes multiple methods. Once the distance/similarity matrix is obtained, by obtaining its principal components, we can visualize the structure (if there is any) within the population

## The function

We have included a function, `pcoa.plot()` that calculates the principal components and variance percentages (using R's own `prcomp()` function) and uses them to plot whatever components are desired (1 and 2 by default). It also includes a little function to add colour to these plots to help dissect the structure. The arguments of `pcoa.plot()` include:

* `K`: any distance/similarity matrix
* `comp`: numeric vector of length 2. The components that are to be used for plotting. A PCoA generates as many components as dimensions had the original distance matrix. They are ordered by their explanatory value (components 1 and 2 will always be the most explanatory). The amount of explained variance of each is always present in the `xlab` and `ylab` of the plot.
* `col`: unlike in most functions, in this case the parameter `col` is expected to be a vector with values (categorical or numeric) that will be used to plot colours upon the scatter plot. For instance, if 5 observations are provided, one can provide a col vector that defines to which population each individual belongs (e.g. c("pop1","pop1","pop2","pop2","pop3")) in which case three colours will be chosen and applied to the points. If a numerical variable is used, a similar process will be followed, obtaining a gradient of colour for the variable. 
* `plot_legend`: logical, whether the legend should be plotted.
* `legpos`: character vector similar to `x` argument in the `legend()` function. The location is specified by setting `x` to a single keyword from the list "bottomright", "bottom", "bottomleft", "left", "topleft", "top", "topright", "right" and "center".
* `legname`: the legend names for the colours chosen, automatically taken from `col` if not specified.

```{r pcoa}
#calculate the similarity matrix K
K <- calc.K(t(dos))

#We must transform the result of dist into a matrix to use it with pcoa.plot()
euc <- as.matrix(dist(t(dos),method = "euclidean"))

pop <- substr(colnames(K),1,2)

pcoa.plot(K,col = pop,legpos = "topright",xlim = c(-0.12,0.12),
          pch=19,main="PCoA plot of K (similarity)")

pcoa.plot(1-K,col = pop,legpos = "topright",xlim = c(-0.12,0.12),
          pch=19,main="PCoA plot of 1-K (distance)")

pcoa.plot(euc,col = pop,legpos = "topright",xlim = c(-0.12,0.12),
          pch=19,main="PCoA plot of Euclidean distance")

#If we want to, we can choose different components of the PCoA, for instance the
#second and third
pcoa.plot(K,col = pop,legpos = "topright",xlim = c(-0.12,0.12),comp = c(1,3),
          pch=19,main="PCoA plot of K (similarity)")
```

## Interpreting PCoA

PCoA plots are interesting but tricky to interpret, let's have a look at them.

A PCoA plot contains a single point for each individual, and the closer two points are, the more similar these individuals are. Generally, the sign and dimensions of the axis are meaningless, so there is no need to worry about them. That also means that two mirrored images in a PCoA are equivalent. It is crucial, as well, to look carefully at the percentage of explained variance of each PC, as this is an indication of the relative importance of that axis in comparison to the original genotype matrix. Let's look at the PCoA plots above. 

All plots show results of a PCoA obtained from the same dosage matrix (`dos`). This dosage matrix contains information about 460 individuals of which 10 are parents and 450 are offspring between one central parent and one of the 9 peripheral parents (following a NAM structure). Moreover, this 10 parents originate, in fact, from 3 different natural populations (labelled A, B and C). The central parent comes from population A, therefore, all offspring is a cross between a parent from A and a parent from A, B or C. These population labels (AxA, AxB, AxC) have been included in the plots, and indicate to which population does each *offspring* belong. All parents, irrespective of their population group, have been lavelled as "parent". 

The first three graphs show the result of three different types of genetic distance/similarity measures, and highlight that the three provide equivalent (yet not exactly the same) results. The graphs cover aproximately 95%, 95% and 81% of the total variance respectively, and thus represent very well the whole distance/similarity matrix. Note that here we have unusually high variance components because we are using **simulated data**, normally we would expect somewhere between 20-40% of explained variance in total. All plots show the same: the parents are three sets of very distinct individuals, very similar between them, and the offsprings are located between the central and the peripheral parents. 

The last graph, however, is very different! We chose to plot components 1 and 3. Component 1 is very informative, but component 3 very little (only 0.68% of the total variance). Thus the spread along the y-axis is, in fact, not very informative. We do see some seemingly interesting patterns in this plot, but they are not trustworthy. PCoA's are tricky to interpret because in many instances they will generate pattern-looking clouds, which might harbour very little actual meaning and just reflect some systematic noise. To look at a more extreme example, let's look at the following graph, where we take PCs 3 and 4:

```{r}
pcoa.plot(K,col = pop,legpos = "topright",xlim = c(-0.16,0.14),comp = c(4,5),
          pch=19,main="PCoA plot of K (similarity)")
```

We feel tempted to try to interpret this plot's seemingly interesting structure, however, the percentage of explained variance of each axis is so small, that the distribution of points in this plane is likely to be meaningless. 

Although this might seem obvious here, there are many scientific papers where, aiming to support their original hypothesis, very unclear PCoA plots are over-interpreted without any statistical solidity, leading to weakly supported claims. A good rule of thumb for PCoA plots then, is to always look for high variance components and for **clear patterns**, rather than obscure interpretations of abstract shapes. 

# P-value visualization

In a QTL analysis some type of significance score is obtained along the genome, either continuously (typically LOD scores) or at discrete marker positions (typically a p-value). In the model implemented in `mpQTL`, significances are expressed as p-values, discretely along the genome. We can study the p-values in two different ways: looking at their overall distribution using Quantile-Quantile plots (QQ-plot) or plotting the significance scores along the genomic map (Manhattan plot, skyline plot in `mpQTL`).

## Quantile-Quantile plot

QQ-plots are useful for determining whether the p-value distribution of a QTL analysis (y axis) follows the expected distribution (x axis). In this case, the expected distribution corresponds to a null hypothesis where there are **no truly significant markers** (there are only a few false positives). This expectation can be seen in the plot with a red diagonal line. 

### The function

The function `comp.QQ()` can be used to generate QQ-plots of one or multiple vectors of p-values. Each vector of p-values can be given as a column in a matrix or as an element of a list. The number of p-values in each vector does not matter. A single set of p-values can also be provided.

```{r qq_plot}
#The p-values are from 500 random normal values
not_sig <- pnorm(rnorm(500),lower.tail = F)

#The p-values are from some random normal values and some non-random
some_sig <- pnorm(c(rnorm(450),rnorm(50,mean = 3)),lower.tail = F)

#The p-values are all too significant
high_sig <- pnorm(rnorm(500,mean=3),lower.tail = F)

#The p-values are all too non-significant
low_sig <- pnorm(rnorm(500),sd = 3,lower.tail = F)

pvals <- list(not_sig,some_sig,high_sig,low_sig)
QQ.plot(pvals,main="Example QQ-plot",
        legnames = c("Not significant",
                     "Good significant",
                     "Overestimated",
                     "Underestimated"))
```

A *legend* is automatically added, but can be deactivated using the argument `plot_legend = F`, and the legend names are extracted from the column names or list element names. In case no names are provided, they're labelled as "pval 1", "pval 2", etc. This can also be changed with the argument `legname` and giving a vector of names.

### Interpreting QQ plots

Our aim when looking at a QQ plot is to evaluate whether the p-values follow an expected p-value distribution, and if they don't, evaluate whether the deviations are due to modelling problems or the detection of a QTL. Above we have plotted four situations, let's have a look at them:

1. **Not significant**: the p-values follow the trend line, there are no more significant tests than expected by chance.
2. **Good significant**: the p-values follow the trend line for most of the points (these points correspond to non-significant markers), except at the tail, where it goes above the trend line (very significant, unexpected markers). This indicates that most markers are behaving according to the null hypothesis (no QTL), and only some deviate. 
3. **Overestimation**: in some cases due to modelling problems (data is not good, genotyping is biased...) the p-values might be systematically **too significant**. In this case we will see the p-value distribution go above the expectation line for most of the plot. This indicates a high chance of false positives and overestimation of significance (i.e. detected QTLs are likely to be false positives).
4. **Underestimation**: in some cases our modelling approach might produce p-values that are systematically **too low**. In this case we will see the p-value distribution go below the expectation line. This indicates a high chance of false negatives and underestimation of significance (i.e. QTLs might exist but will not be detected). 

Lastly, we might be able to apply multiple models to the same data (for instance, including extra cofactors), producing different results. We are then forced to choose which model to trust, which might be difficult if there are no obvious differences between the models suitability. We might then use QQ plots to compare the distributions of multiple models to evaluate whether we are in one of the previously described scenarios with any of the models. 

## Skyline plot

Probably the most relevant plot for QTL mapping is the "Manhattan plot", named as such due to its structure, which can remind of the skyline of of the famous skyscraper district of New York. In this package, we have opted to name the function `skyplot()`, following the visual metaphor. 

A Manhattan plot is a form of marker significance visualization that helps us recognise regions where multiple significant markers co-locate around a region, defining a QTL location. On the x-axis the marker's position in the genome (physical or genetic) and on the y-axis, the marker's significance. Generally, significance is expressed as $-log10(pval)$, but any other score will do, as long as it follows that more significant markers have higher scores, and less significant markers have lower scores (for instance a Wald score or F-test). 

### The function

To generate the visualization one must provide both p-values and a genetic/physical map. The `skyplot()` function has the following arguments:

* `pval`: vector of pvalues. Importantly, the function `-log10()` must be performed by the user. This has been done on purpose, as we might want to plot other kind of score values with this function that do not require the -log10 transformation.
* `map`: a genetic map data.frame with at least columns "position" and "chromosome".
* `threshold`: numeric, optional value to draw a threshold line.
* `chrom`: numeric or character vector. If provided, it is used to select the p-values based on the "chromosome" column of `map`.
* `small`: logical, should the cM scale be drawn? By default it will only be drawn if only two or a single chromosome are plotted, otherwise it is too crowded and barely legible.
* `...`: other parameters can be passed to the `plot()` function. The most relevant are probably `main` for the title, `ylab` for the label on the y axis and `xlab` for the label of the x axis.

```{r skyplot}
#Just a skyline plot
skyplot(-log10(pv),map = map,main="Example Skyline plot")

#We want to focus on chromosome 1
skyplot(-log10(pv),map,chrom = 1,main ="Skyline lot of chromosome 1",threshold = 3.6)

#The "chromosomes" can also be expressed as characters
map_letters <- map
map_letters$chromosome <- LETTERS[map_letters$chromosome + 1]

skyplot(-log10(pv),map_letters,main="Skyline plot where chromosomes are characters",
        chrom = sample(unique(map_letters$chromosome),2),small = T)

```
 
For our research, we wanted to compare the skyline plots of multiple models, namely the haplotype-based and dosage-based models. For that reason, another skyline plot function was developed: `comp.skplot()`. The function is used in a very similar fashion, with some differences:

* `pval`: each p-value vector must be provided as a column in a matrix or a vector in a list. 
* `map`: a map must be provided for each set of p-values. If a single map is provided, it will be assumed that all p-value vectors correspond to the same map. For the moment, we have not tested what happens if each map has a different set of chromosomes (i.e. map1 has chromosomes 1, 2 and 3 and map2 has chromosomes 1, 2 and 4), that might cause conflicts.
* `chrom`: similarly, we have not tested what would happen if chromosomes are selected that are present only in one of the two maps. This will be looked into.
* `legnames`: a vector of names for the legend elements. If not provided, it will be read from the pvalue list, and if the list has no names, it will be simply labelled pval 1, pval 2, etc.

```{r comp_skyplot}
pv2 <- data$result[[2]]$pval

comp.skyplot(list(-log10(pv),-log10(pv2)),map,main = "Comparison of two p-value distributions",threshold = 4)
```

### Interpreting skyline plots

Skyline plots are very easy to interpret since they are so intuitively eloquent. The higher the peak, the more significant a marker/region is, the stronger the QTL effect must be on the trait in question. 

To define a **QTL region** we use a threshold, which for the moment we are calculating using a permutation threshold, which accounts for multiple testing. All markers above the threshold should be considered significant, and thus we can define a QTL region in every place where a series of close markers are above the threshold. 

One can **compare skyline plots** between different phenotypes to see if the same or similar region are detected using different phenotypes, since that might indicate that a single QTL has effect on both traits. 

# Phenotype boxplot

It is useful to correlate the dosage of a single marker with the value of a phenotype, as sometimes that can reveal "dosage effects", as was saw for instance in the work of Giorgio Tumino and petal number in rose with the locus ... In order to simplify the process of generating such boxplots, we have created a wrapper that makes them using dosages or haplotypes let us see how. 

### The function

There is a single function, `pheno_box()` that can use two different methods, either for dosages or for haplotypes, by changing the parameter `haplotype` (False by default). Some parameters behave identically no matter what the value of `haplotype` is:

* `phe`: is a numerical vector of phenotypes
* `gen`: if haplotype = F, `gen` should be a numeric vector of dosages with a single observation per individual. If haplotype = T, `gen` should be a vector with $p$ numeric/character observations per individual where $p$ is the ploidy, and each observation is a haplotype class (e.g. 120, 140, 128...;A, B, C...; hap1, hap2, hap3...)
* `draw.points`: is a logical that indicates whether points should be drawn.
* `...`: further arguments to be passed to `plot()`

When `haplotype = T` other parameters can be used:
* `ploidy`: is an integer indicating the ploidy.
* `hap.select`: is a vector of numeric/character indicating which haplotypes should be plotted.

```{r phe_box}
gen_dos <- unlist(dos[4,])
gen_hap <- unlist(hap[4,])

pheno_box(phe[,1],gen_dos,
          xlab="Dosage",ylab="phenotype",main="A boxplot of dosages")

#But now there are too many things plotted and I can't see anything
pheno_box(phe[,1],gen_hap,haplotype = T,ploidy = 4,
          xlab="Haplotypes",ylab="phenotype",main="A boxplot of haplotype dosages")

#This is better but still too many boxes
pheno_box(phe[,1],gen_hap,haplotype = T,ploidy = 4,draw.points = F,
          xlab="Haplotypes",ylab="phenotype",main="A boxplot of haplotype dosages (no points)")

#This is better
pheno_box(phe[,1],gen_hap,haplotype = T,ploidy = 4, hap.select = c(50,10,77,45),
          xlab="Haplotypes",ylab="phenotype",main="A boxplot of some haplotype dosages")
```

# Colour choice

The colour system of the visualization functions in the mpQTL package is a bit different than the default methods that most R plots include. To perform colour choice we use the package `colorspace`, which uses the HCL (hue, color tone; chrome, coloyr intensity; and luminance, colour lightness) system to define colour. This package has been designed with data visualization in mind and offers great functionalities for intelligent and effective colour choice. If you are interested, I highly recommend visiting their [web page](http://colorspace.r-forge.r-project.org/), where they explain the package and many important concepts of colour theory and design. 

For our purposes, there are two main types of colour palettes we can make: **qualitative** or **sequential**. The first type of palette chooses different *hues* of colour (red, green, blue...) while the second one chooses different *luminances* (from dark to light) of the same hue. Additionally, **divergent** colour palettes can be used, which set middle values to white and extreme values to two opposing hues, allowing us to highlight extreme values. Which palette type whe choose will depend on the data we try to visualize:

* In *categorical variables* all categories are of equal importance, and thus a *qualitative* palette will be most useful. However, if there are more than 7 categories, it is advised to avoid qualitative palettes with many hues and instead use *sequential* palettes, since with 8 or more colours it is hard to keep track of all categories and distinguish all hues.

* With *numerical variables* that are ordered, *sequential* palettes, are the most useful. Our eyes will instinctively give the most importance to the darker colours, and thus these palettes are useful to highlight very high or very low values. Also, when there are many categories, sequential palettes can be used to avoid having many colours. If we are using values that can be very negative or very positive (like temperatures), *divergent* palettes might be the most useful.

There are other types of palettes that can be useful, but we will not discuss them here. 

### The function

In all plotting functions, two extra parameters can be chosen: 

* `coltype`: standing for colour palette type, we can choose between "sequential", "qualitative", "divergent" or "rainbow". 
* `h`: one or two numerical values, standing for hue. The values are degrees within the colour wheel, and thus values between 0 and 360 are recommended, where 0 and 360 are the same. For a colour reference you can use `hue_wheel()` which produces the plot below.
* `l`: one (for qualitative) or two (for sequential) numerical values. This controls the lightness of the colours, by default set to 60. Values should be between 20 and 100, below or above the results will be unexpected.

```{r hue_wheel,echo = F,fig.show="hold",fig.height=5,fig.width=5,out.width=340}
hue_wheel(l=40)
hue_wheel()
hue_wheel(l=100)
```

With this system, changing the colours of any plot is pretty straight-forward. You can specify a different pair of values for `h`, to create a gradient between these two colours (in qualitative palettes) or a single `h` for sequential palettes. To switch between sequential and qualitative palettes simply change the `coltype` parameter. If you would like a stronger light-dark contrast in sequential palettes, choose more extreme `l` values, `c(20,90)` by default, or if you would like less contrast, choose closer values. For qualitative palettes, you can use this parameter to obtain lighter, or darker colours. 

As a final note, since the colours are expressed in degrees, 0, 360, 720 and 1080 all refer to the same hue: red. If you set a qualitative gradient between 0 and 10, the palette will start at red and end at a very similar red (so all colours will be very similar). If, instead, you give 0 and 370 as the `h` value, the colours will start and end at these reds, but going through the whole colour wheel, giving a sort-of rainbow palette. 

